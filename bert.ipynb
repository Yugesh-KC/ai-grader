{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Reads the text content from a PDF file and returns it as a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The concatenated text content of all pages in the PDF.\n",
    "    \"\"\"\n",
    "    # Logic to read pdf\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    # Loop over each page and store it in a variable\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = load_pdf(file_path=\"try.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_text(text: str):\n",
    "    \"\"\"\n",
    "    Splits a text string into a list of non-empty substrings based on the specified pattern.\n",
    "    The \"\\n \\n\" pattern will split the document para by para\n",
    "    Parameters:\n",
    "    - text (str): The input text to be split.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing non-empty substrings obtained by splitting the input text.\n",
    "\n",
    "    \"\"\"\n",
    "    split_text = re.split('\\n \\n', text)\n",
    "    return [i for i in split_text if i != \"\"]\n",
    "\n",
    "chunked_text = split_text(text=pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import os\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"\n",
    "    Custom embedding function using the Gemini AI API for document retrieval.\n",
    "\n",
    "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
    "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
    "\n",
    "    Parameters:\n",
    "    - input (Documents): A collection of documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - Embeddings: Embeddings generated for the input documents.\n",
    "    \"\"\"\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = \"models/embedding-001\"\n",
    "        title = \"Custom query\"\n",
    "        return genai.embed_content(model=model,\n",
    "                                   content=input,\n",
    "                                   task_type=\"retrieval_document\",\n",
    "                                   title=title)[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from typing import List\n",
    "def create_chroma_db(documents:List, path:str, name:str):\n",
    "    \"\"\"\n",
    "    Creates a Chroma database using the provided documents, path, and collection name.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: An iterable of documents to be added to the Chroma database.\n",
    "    - path (str): The path where the Chroma database will be stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    for i, d in enumerate(documents):\n",
    "        db.add(documents=d, ids=str(i))\n",
    "\n",
    "    return db, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db,name =create_chroma_db(documents=chunked_text, \n",
    "                          path=\"new.pdf\", #replace with your path\n",
    "                          name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_collection(path, name):\n",
    "    \"\"\"\n",
    "    Loads an existing Chroma collection from the specified path with the given name.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The path where the Chroma database is stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - chromadb.Collection: The loaded Chroma Collection.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=load_chroma_collection(path=\"new.pdf\", name=\"rag_experiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db, n_results):\n",
    "  passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "  return passage\n",
    "\n",
    "#Example usage\n",
    "relevant_text = get_relevant_passage(query=\"how to make corba\",db=db,n_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' \\uf0a1 Corba Component Model \\nThe component model specifies how interfaces should be defined and the elements that should \\nbe included in an int erface definition ', 'Elements of components model ', ' \\n6.2. Components \\nComponents provide a service wit hout regard to where the compon ent is executing or its \\nprogramming language \\n\\uf0a1 A component is an independent executable entity that can be mad e up of one or more \\nexecutable objects; \\n\\uf0a1 The component interface is publis hed and all interactions are t hrough the published \\ninterface; \\nA software component is a software element that  conforms to a component model and can be \\nindependently deployed and composed without modification according to a composition \\nstandard. -  Councill and Heinmann:  A softw a\\nexplicit c\\nsubject t o']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_prompt(query, full_marks, ideal_answer, relevant_text, students_answer):\n",
    "    \"\"\"\n",
    "    Generates a grading prompt for a teacher checking an engineering exam paper.\n",
    "    \n",
    "    Parameters:\n",
    "    - query: The exam question.\n",
    "    - full_marks: The full marks allocated for the question.\n",
    "    - ideal_answer: The ideal or model answer for the question.\n",
    "    - relevant_text: The relevant reference text to be used in grading.\n",
    "    - students_answer: The answer provided by the student.\n",
    "\n",
    "    Returns:\n",
    "    - A formatted prompt that can be used to grade the student's answer.\n",
    "    \"\"\"\n",
    "    # Escape special characters to ensure proper formatting\n",
    "    escaped_relevant_text = relevant_text.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "    if ideal_answer:\n",
    "        ideal_answer = ideal_answer.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "\n",
    "    # Format the grading prompt with all the necessary information\n",
    "    prompt = f\"\"\"\n",
    "    You are a teacher checking Bachelor's in Engineering exam papers. You will be given a question, its full marks, the ideal answer, \n",
    "    the relevant reference text, and the answer given by the student. Your task is to grade the student's answer strictly, keeping in mind \n",
    "    the full marks allocated for the question. If the ideal answer and relevant text lacks important information, use your own judgment and intuition \n",
    "    to evaluate the answer based on the provided reference text.\n",
    "\n",
    "    Be sure to evaluate the completeness, accuracy, and clarity of the student's response while being fair and consistent with the marks.\n",
    "\n",
    "    QUESTION: '{query}'\n",
    "    Full Marks: {full_marks}\n",
    "    Ideal Answer: '{ideal_answer}'\n",
    "    Relevant Reference Text: '{escaped_relevant_text}'\n",
    "    \n",
    "    Student's Answer: '{students_answer}'\n",
    "\n",
    "    GRADE:\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "def generate_answers(prompt):\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    answer = model.generate_content(prompt)\n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_final_function(db, query, full_marks, students_answer, ideal_answer=None, n_results=3):\n",
    "    \"\"\"\n",
    "    Generates an answer based on a student's response, relevant reference text, and an ideal answer.\n",
    "    \n",
    "    Parameters:\n",
    "    - db: The Chroma database for retrieving relevant text.\n",
    "    - query: The exam question.\n",
    "    - full_marks: The full marks allocated for the question.\n",
    "    - students_answer: The answer provided by the student.\n",
    "    - ideal_answer: The ideal answer, if available (defaults to None).\n",
    "    - n_results: The number of relevant text chunks to retrieve (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    - The generated grade or evaluation based on the prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the top N relevant text chunks for the query\n",
    "    relevant_text_chunks = get_relevant_passage(query, db, n_results=n_results)\n",
    "    \n",
    "    # If no relevant text is found, return a default message\n",
    "    if not relevant_text_chunks:\n",
    "        return \"No relevant information found for grading.\"\n",
    "\n",
    "    # Combine the retrieved text chunks into one passage\n",
    "    relevant_text = \" \".join(relevant_text_chunks)\n",
    "    \n",
    "    print(ideal_answer)\n",
    "    # If no ideal answer is provided, use None\n",
    "    \n",
    "    # Generate the grading prompt using the ideal answer (if available) and student answer\n",
    "    prompt = make_rag_prompt(query, full_marks, ideal_answer=ideal_answer,  relevant_text=relevant_text, students_answer=students_answer)\n",
    "    \n",
    "    # Generate the answer or evaluation from the model based on the prompt\n",
    "    answer = generate_answers(prompt)\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORBA is the Common Object Request Broker Architecture, a specification that defines how distributed objects can communicate with each other in a heterogeneous network environment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"5 out of 5\\n\\nThe student's answer is complete, accurate, and clear. It matches the ideal answer perfectly. The student has demonstrated a good understanding of the concept of CORBA.\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_final_function(db,\"what is corba?\",full_marks=5,ideal_answer='',students_answer=\"CORBA is the Common Object Request Broker Architecture, a specification that defines how distributed objects can communicate with each other in a heterogeneous network environment.\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
